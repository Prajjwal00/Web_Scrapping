# Web_Scrapping
Web Scrapping of top 30 github repositories 
using Pandas ,BeautifulSoup and response
## How it works
- Web Scrapers can extract all the data on particular sites or the specific data that a user wants. Ideally, itâ€™s best if you specify the data you want so that the web scraper only extracts that data quickly.
- For example, you might want to scrape an Amazon page for the types of juicers available, but you might only want the data about the models of different juicers and not the customer reviews. 
- So, when a web scraper needs to scrape a site, first the URLs are provided. 
- Then it loads all the HTML code for those sites and a more advanced scraper might even extract all the CSS and Javascript elements as well. Then the scraper obtains the required data from this HTML code and outputs this data in the format specified by the user. 
- Mostly, this is in the form of an Excel spreadsheet or a CSV file, but the data can also be saved in other formats, such as a JSON file.
## Beautiful Soup
- Beautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner.
